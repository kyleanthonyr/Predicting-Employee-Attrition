{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f6449c6",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2168e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_auc_score, recall_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "# set custom pd settings\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb3f3ef",
   "metadata": {},
   "source": [
    "## Import train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a7eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv')\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4628f2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_age</th>\n",
       "      <th>sub_health_h</th>\n",
       "      <th>sub_commitment_h</th>\n",
       "      <th>sub_perceptiveness_h</th>\n",
       "      <th>sub_dexterity_h</th>\n",
       "      <th>sub_sociality_h</th>\n",
       "      <th>sub_goodness_h</th>\n",
       "      <th>sub_strength_h</th>\n",
       "      <th>sub_openmindedness_h</th>\n",
       "      <th>sup_age</th>\n",
       "      <th>sup_sub_age_diff</th>\n",
       "      <th>sup_commitment_h</th>\n",
       "      <th>sup_perceptiveness_h</th>\n",
       "      <th>sup_goodness_h</th>\n",
       "      <th>Num Underrecorded Efficacy</th>\n",
       "      <th>Num Mismatched Events</th>\n",
       "      <th>sub_sex_F</th>\n",
       "      <th>sub_sex_M</th>\n",
       "      <th>sub_shift_Shift 1</th>\n",
       "      <th>sub_shift_Shift 2</th>\n",
       "      <th>sub_shift_Shift 3</th>\n",
       "      <th>sub_team_Team 1</th>\n",
       "      <th>sub_team_Team 10</th>\n",
       "      <th>sub_team_Team 11</th>\n",
       "      <th>sub_team_Team 12</th>\n",
       "      <th>sub_team_Team 13</th>\n",
       "      <th>sub_team_Team 14</th>\n",
       "      <th>sub_team_Team 15</th>\n",
       "      <th>sub_team_Team 16</th>\n",
       "      <th>sub_team_Team 17</th>\n",
       "      <th>sub_team_Team 18</th>\n",
       "      <th>sub_team_Team 19</th>\n",
       "      <th>sub_team_Team 2</th>\n",
       "      <th>sub_team_Team 20</th>\n",
       "      <th>sub_team_Team 21</th>\n",
       "      <th>sub_team_Team 22</th>\n",
       "      <th>sub_team_Team 23</th>\n",
       "      <th>sub_team_Team 24</th>\n",
       "      <th>sub_team_Team 3</th>\n",
       "      <th>sub_team_Team 4</th>\n",
       "      <th>sub_team_Team 5</th>\n",
       "      <th>sub_team_Team 6</th>\n",
       "      <th>sub_team_Team 7</th>\n",
       "      <th>sub_team_Team 8</th>\n",
       "      <th>sub_team_Team 9</th>\n",
       "      <th>sub_team_unassigned</th>\n",
       "      <th>sub_role_Laborer</th>\n",
       "      <th>sub_role_Shift Manager</th>\n",
       "      <th>sub_role_Team Leader</th>\n",
       "      <th>sub_workstyle_h_Group A</th>\n",
       "      <th>sub_workstyle_h_Group B</th>\n",
       "      <th>sub_workstyle_h_Group C</th>\n",
       "      <th>sub_workstyle_h_Group D</th>\n",
       "      <th>sub_workstyle_h_Group E</th>\n",
       "      <th>sup_sex_F</th>\n",
       "      <th>sup_sex_M</th>\n",
       "      <th>sup_role_Shift Manager</th>\n",
       "      <th>sup_role_Team Leader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.527432</td>\n",
       "      <td>0.707460</td>\n",
       "      <td>-1.127066</td>\n",
       "      <td>0.153136</td>\n",
       "      <td>-0.920603</td>\n",
       "      <td>0.926109</td>\n",
       "      <td>-0.358535</td>\n",
       "      <td>0.515376</td>\n",
       "      <td>-1.696963</td>\n",
       "      <td>0.964016</td>\n",
       "      <td>-0.357598</td>\n",
       "      <td>1.546008</td>\n",
       "      <td>0.389179</td>\n",
       "      <td>1.387348</td>\n",
       "      <td>0.872806</td>\n",
       "      <td>1.138468</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.600625</td>\n",
       "      <td>0.575450</td>\n",
       "      <td>1.604127</td>\n",
       "      <td>-1.291524</td>\n",
       "      <td>-0.426578</td>\n",
       "      <td>0.449880</td>\n",
       "      <td>1.304687</td>\n",
       "      <td>-2.530059</td>\n",
       "      <td>-1.354781</td>\n",
       "      <td>-0.145963</td>\n",
       "      <td>-1.229461</td>\n",
       "      <td>-0.021949</td>\n",
       "      <td>-0.026958</td>\n",
       "      <td>1.729004</td>\n",
       "      <td>0.872806</td>\n",
       "      <td>0.811144</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.381046</td>\n",
       "      <td>0.166217</td>\n",
       "      <td>0.509011</td>\n",
       "      <td>-0.373362</td>\n",
       "      <td>-0.615088</td>\n",
       "      <td>1.304650</td>\n",
       "      <td>-0.706957</td>\n",
       "      <td>0.838953</td>\n",
       "      <td>-1.012600</td>\n",
       "      <td>-0.770327</td>\n",
       "      <td>-1.537177</td>\n",
       "      <td>-0.480165</td>\n",
       "      <td>-1.961433</td>\n",
       "      <td>-1.744498</td>\n",
       "      <td>0.733680</td>\n",
       "      <td>2.120442</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.381046</td>\n",
       "      <td>0.153016</td>\n",
       "      <td>-0.856586</td>\n",
       "      <td>0.487013</td>\n",
       "      <td>-0.569586</td>\n",
       "      <td>0.230082</td>\n",
       "      <td>0.765619</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>-0.683091</td>\n",
       "      <td>0.409026</td>\n",
       "      <td>-0.665315</td>\n",
       "      <td>0.085445</td>\n",
       "      <td>0.136123</td>\n",
       "      <td>0.431977</td>\n",
       "      <td>-1.878785</td>\n",
       "      <td>-1.152804</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.741544</td>\n",
       "      <td>0.872473</td>\n",
       "      <td>-0.566314</td>\n",
       "      <td>-0.630190</td>\n",
       "      <td>-0.264070</td>\n",
       "      <td>1.475604</td>\n",
       "      <td>0.443493</td>\n",
       "      <td>-2.098622</td>\n",
       "      <td>-0.936559</td>\n",
       "      <td>0.339653</td>\n",
       "      <td>0.770694</td>\n",
       "      <td>0.214318</td>\n",
       "      <td>1.007762</td>\n",
       "      <td>-0.814435</td>\n",
       "      <td>-0.193822</td>\n",
       "      <td>-0.825479</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sub_age  sub_health_h  sub_commitment_h  sub_perceptiveness_h  \\\n",
       "0  1.527432      0.707460         -1.127066              0.153136   \n",
       "1  1.600625      0.575450          1.604127             -1.291524   \n",
       "2  1.381046      0.166217          0.509011             -0.373362   \n",
       "3  1.381046      0.153016         -0.856586              0.487013   \n",
       "4 -0.741544      0.872473         -0.566314             -0.630190   \n",
       "\n",
       "   sub_dexterity_h  sub_sociality_h  sub_goodness_h  sub_strength_h  \\\n",
       "0        -0.920603         0.926109       -0.358535        0.515376   \n",
       "1        -0.426578         0.449880        1.304687       -2.530059   \n",
       "2        -0.615088         1.304650       -0.706957        0.838953   \n",
       "3        -0.569586         0.230082        0.765619        0.007803   \n",
       "4        -0.264070         1.475604        0.443493       -2.098622   \n",
       "\n",
       "   sub_openmindedness_h   sup_age  sup_sub_age_diff  sup_commitment_h  \\\n",
       "0             -1.696963  0.964016         -0.357598          1.546008   \n",
       "1             -1.354781 -0.145963         -1.229461         -0.021949   \n",
       "2             -1.012600 -0.770327         -1.537177         -0.480165   \n",
       "3             -0.683091  0.409026         -0.665315          0.085445   \n",
       "4             -0.936559  0.339653          0.770694          0.214318   \n",
       "\n",
       "   sup_perceptiveness_h  sup_goodness_h  Num Underrecorded Efficacy  \\\n",
       "0              0.389179        1.387348                    0.872806   \n",
       "1             -0.026958        1.729004                    0.872806   \n",
       "2             -1.961433       -1.744498                    0.733680   \n",
       "3              0.136123        0.431977                   -1.878785   \n",
       "4              1.007762       -0.814435                   -0.193822   \n",
       "\n",
       "   Num Mismatched Events  sub_sex_F  sub_sex_M  sub_shift_Shift 1  \\\n",
       "0               1.138468          0          1                  0   \n",
       "1               0.811144          1          0                  0   \n",
       "2               2.120442          0          1                  0   \n",
       "3              -1.152804          0          1                  0   \n",
       "4              -0.825479          1          0                  0   \n",
       "\n",
       "   sub_shift_Shift 2  sub_shift_Shift 3  sub_team_Team 1  sub_team_Team 10  \\\n",
       "0                  0                  1                0                 0   \n",
       "1                  1                  0                0                 0   \n",
       "2                  1                  0                0                 1   \n",
       "3                  1                  0                0                 0   \n",
       "4                  0                  1                0                 0   \n",
       "\n",
       "   sub_team_Team 11  sub_team_Team 12  sub_team_Team 13  sub_team_Team 14  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 1                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 1   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   sub_team_Team 15  sub_team_Team 16  sub_team_Team 17  sub_team_Team 18  \\\n",
       "0                 0                 0                 0                 1   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   sub_team_Team 19  sub_team_Team 2  sub_team_Team 20  sub_team_Team 21  \\\n",
       "0                 0                0                 0                 0   \n",
       "1                 0                0                 0                 0   \n",
       "2                 0                0                 0                 0   \n",
       "3                 0                0                 0                 0   \n",
       "4                 0                0                 0                 0   \n",
       "\n",
       "   sub_team_Team 22  sub_team_Team 23  sub_team_Team 24  sub_team_Team 3  \\\n",
       "0                 0                 0                 0                0   \n",
       "1                 0                 0                 0                0   \n",
       "2                 0                 0                 0                0   \n",
       "3                 0                 0                 0                0   \n",
       "4                 0                 0                 1                0   \n",
       "\n",
       "   sub_team_Team 4  sub_team_Team 5  sub_team_Team 6  sub_team_Team 7  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   sub_team_Team 8  sub_team_Team 9  sub_team_unassigned  sub_role_Laborer  \\\n",
       "0                0                0                    0                 0   \n",
       "1                0                0                    0                 1   \n",
       "2                0                0                    0                 1   \n",
       "3                0                0                    0                 1   \n",
       "4                0                0                    0                 1   \n",
       "\n",
       "   sub_role_Shift Manager  sub_role_Team Leader  sub_workstyle_h_Group A  \\\n",
       "0                       0                     1                        1   \n",
       "1                       0                     0                        0   \n",
       "2                       0                     0                        0   \n",
       "3                       0                     0                        1   \n",
       "4                       0                     0                        0   \n",
       "\n",
       "   sub_workstyle_h_Group B  sub_workstyle_h_Group C  sub_workstyle_h_Group D  \\\n",
       "0                        0                        0                        0   \n",
       "1                        0                        1                        0   \n",
       "2                        0                        1                        0   \n",
       "3                        0                        0                        0   \n",
       "4                        0                        1                        0   \n",
       "\n",
       "   sub_workstyle_h_Group E  sup_sex_F  sup_sex_M  sup_role_Shift Manager  \\\n",
       "0                        0          1          0                       1   \n",
       "1                        0          0          1                       0   \n",
       "2                        0          0          1                       0   \n",
       "3                        0          0          1                       0   \n",
       "4                        0          1          0                       0   \n",
       "\n",
       "   sup_role_Team Leader  \n",
       "0                     0  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df5692e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_age</th>\n",
       "      <th>sub_health_h</th>\n",
       "      <th>sub_commitment_h</th>\n",
       "      <th>sub_perceptiveness_h</th>\n",
       "      <th>sub_dexterity_h</th>\n",
       "      <th>sub_sociality_h</th>\n",
       "      <th>sub_goodness_h</th>\n",
       "      <th>sub_strength_h</th>\n",
       "      <th>sub_openmindedness_h</th>\n",
       "      <th>sup_age</th>\n",
       "      <th>sup_sub_age_diff</th>\n",
       "      <th>sup_commitment_h</th>\n",
       "      <th>sup_perceptiveness_h</th>\n",
       "      <th>sup_goodness_h</th>\n",
       "      <th>Num Underrecorded Efficacy</th>\n",
       "      <th>Num Mismatched Events</th>\n",
       "      <th>sub_sex_F</th>\n",
       "      <th>sub_sex_M</th>\n",
       "      <th>sub_shift_Shift 1</th>\n",
       "      <th>sub_shift_Shift 2</th>\n",
       "      <th>sub_shift_Shift 3</th>\n",
       "      <th>sub_team_Team 1</th>\n",
       "      <th>sub_team_Team 10</th>\n",
       "      <th>sub_team_Team 11</th>\n",
       "      <th>sub_team_Team 12</th>\n",
       "      <th>sub_team_Team 13</th>\n",
       "      <th>sub_team_Team 14</th>\n",
       "      <th>sub_team_Team 15</th>\n",
       "      <th>sub_team_Team 16</th>\n",
       "      <th>sub_team_Team 17</th>\n",
       "      <th>sub_team_Team 18</th>\n",
       "      <th>sub_team_Team 19</th>\n",
       "      <th>sub_team_Team 2</th>\n",
       "      <th>sub_team_Team 20</th>\n",
       "      <th>sub_team_Team 21</th>\n",
       "      <th>sub_team_Team 22</th>\n",
       "      <th>sub_team_Team 23</th>\n",
       "      <th>sub_team_Team 24</th>\n",
       "      <th>sub_team_Team 3</th>\n",
       "      <th>sub_team_Team 4</th>\n",
       "      <th>sub_team_Team 5</th>\n",
       "      <th>sub_team_Team 6</th>\n",
       "      <th>sub_team_Team 7</th>\n",
       "      <th>sub_team_Team 8</th>\n",
       "      <th>sub_team_Team 9</th>\n",
       "      <th>sub_team_unassigned</th>\n",
       "      <th>sub_role_Laborer</th>\n",
       "      <th>sub_role_Shift Manager</th>\n",
       "      <th>sub_role_Team Leader</th>\n",
       "      <th>sub_workstyle_h_Group A</th>\n",
       "      <th>sub_workstyle_h_Group B</th>\n",
       "      <th>sub_workstyle_h_Group C</th>\n",
       "      <th>sub_workstyle_h_Group D</th>\n",
       "      <th>sub_workstyle_h_Group E</th>\n",
       "      <th>sup_sex_F</th>\n",
       "      <th>sup_sex_M</th>\n",
       "      <th>sup_role_Shift Manager</th>\n",
       "      <th>sup_role_Team Leader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.527432</td>\n",
       "      <td>-2.460790</td>\n",
       "      <td>-0.434372</td>\n",
       "      <td>1.141926</td>\n",
       "      <td>0.418465</td>\n",
       "      <td>1.438971</td>\n",
       "      <td>-0.726679</td>\n",
       "      <td>0.109318</td>\n",
       "      <td>0.780686</td>\n",
       "      <td>0.894643</td>\n",
       "      <td>-0.408885</td>\n",
       "      <td>1.395656</td>\n",
       "      <td>-1.230381</td>\n",
       "      <td>1.608792</td>\n",
       "      <td>0.950098</td>\n",
       "      <td>0.483819</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.673818</td>\n",
       "      <td>-1.338701</td>\n",
       "      <td>-1.588862</td>\n",
       "      <td>0.474172</td>\n",
       "      <td>-1.167616</td>\n",
       "      <td>0.089655</td>\n",
       "      <td>-0.634643</td>\n",
       "      <td>1.517832</td>\n",
       "      <td>0.185036</td>\n",
       "      <td>-1.047822</td>\n",
       "      <td>-1.947466</td>\n",
       "      <td>0.844365</td>\n",
       "      <td>1.131478</td>\n",
       "      <td>-1.206706</td>\n",
       "      <td>-1.492325</td>\n",
       "      <td>-1.152804</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.473472</td>\n",
       "      <td>-1.259495</td>\n",
       "      <td>-2.103435</td>\n",
       "      <td>1.308864</td>\n",
       "      <td>1.114000</td>\n",
       "      <td>1.493921</td>\n",
       "      <td>-2.028331</td>\n",
       "      <td>-0.499769</td>\n",
       "      <td>1.433366</td>\n",
       "      <td>-0.145963</td>\n",
       "      <td>0.924553</td>\n",
       "      <td>-0.021949</td>\n",
       "      <td>-0.026958</td>\n",
       "      <td>1.729004</td>\n",
       "      <td>1.011931</td>\n",
       "      <td>1.465793</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.668352</td>\n",
       "      <td>0.159617</td>\n",
       "      <td>0.581579</td>\n",
       "      <td>-2.980170</td>\n",
       "      <td>1.205005</td>\n",
       "      <td>1.414549</td>\n",
       "      <td>1.705701</td>\n",
       "      <td>0.654958</td>\n",
       "      <td>0.083649</td>\n",
       "      <td>-1.533438</td>\n",
       "      <td>-0.665315</td>\n",
       "      <td>0.493543</td>\n",
       "      <td>-0.414978</td>\n",
       "      <td>0.273803</td>\n",
       "      <td>-1.152241</td>\n",
       "      <td>-0.498155</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.668352</td>\n",
       "      <td>-1.107683</td>\n",
       "      <td>-0.962139</td>\n",
       "      <td>1.052036</td>\n",
       "      <td>0.606974</td>\n",
       "      <td>-0.343836</td>\n",
       "      <td>-2.435919</td>\n",
       "      <td>-0.277706</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>0.339653</td>\n",
       "      <td>0.719408</td>\n",
       "      <td>0.214318</td>\n",
       "      <td>1.007762</td>\n",
       "      <td>-0.814435</td>\n",
       "      <td>0.671847</td>\n",
       "      <td>1.793117</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sub_age  sub_health_h  sub_commitment_h  sub_perceptiveness_h  \\\n",
       "0  1.527432     -2.460790         -0.434372              1.141926   \n",
       "1  1.673818     -1.338701         -1.588862              0.474172   \n",
       "2 -1.473472     -1.259495         -2.103435              1.308864   \n",
       "3 -0.668352      0.159617          0.581579             -2.980170   \n",
       "4 -0.668352     -1.107683         -0.962139              1.052036   \n",
       "\n",
       "   sub_dexterity_h  sub_sociality_h  sub_goodness_h  sub_strength_h  \\\n",
       "0         0.418465         1.438971       -0.726679        0.109318   \n",
       "1        -1.167616         0.089655       -0.634643        1.517832   \n",
       "2         1.114000         1.493921       -2.028331       -0.499769   \n",
       "3         1.205005         1.414549        1.705701        0.654958   \n",
       "4         0.606974        -0.343836       -2.435919       -0.277706   \n",
       "\n",
       "   sub_openmindedness_h   sup_age  sup_sub_age_diff  sup_commitment_h  \\\n",
       "0              0.780686  0.894643         -0.408885          1.395656   \n",
       "1              0.185036 -1.047822         -1.947466          0.844365   \n",
       "2              1.433366 -0.145963          0.924553         -0.021949   \n",
       "3              0.083649 -1.533438         -0.665315          0.493543   \n",
       "4             -0.550021  0.339653          0.719408          0.214318   \n",
       "\n",
       "   sup_perceptiveness_h  sup_goodness_h  Num Underrecorded Efficacy  \\\n",
       "0             -1.230381        1.608792                    0.950098   \n",
       "1              1.131478       -1.206706                   -1.492325   \n",
       "2             -0.026958        1.729004                    1.011931   \n",
       "3             -0.414978        0.273803                   -1.152241   \n",
       "4              1.007762       -0.814435                    0.671847   \n",
       "\n",
       "   Num Mismatched Events  sub_sex_F  sub_sex_M  sub_shift_Shift 1  \\\n",
       "0               0.483819          1          0                  0   \n",
       "1              -1.152804          1          0                  0   \n",
       "2               1.465793          0          1                  0   \n",
       "3              -0.498155          0          1                  1   \n",
       "4               1.793117          1          0                  0   \n",
       "\n",
       "   sub_shift_Shift 2  sub_shift_Shift 3  sub_team_Team 1  sub_team_Team 10  \\\n",
       "0                  1                  0                0                 0   \n",
       "1                  0                  1                0                 0   \n",
       "2                  1                  0                0                 0   \n",
       "3                  0                  0                0                 0   \n",
       "4                  0                  1                0                 0   \n",
       "\n",
       "   sub_team_Team 11  sub_team_Team 12  sub_team_Team 13  sub_team_Team 14  \\\n",
       "0                 0                 1                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 1                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   sub_team_Team 15  sub_team_Team 16  sub_team_Team 17  sub_team_Team 18  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   sub_team_Team 19  sub_team_Team 2  sub_team_Team 20  sub_team_Team 21  \\\n",
       "0                 0                0                 0                 0   \n",
       "1                 0                0                 0                 1   \n",
       "2                 0                0                 0                 0   \n",
       "3                 0                0                 0                 0   \n",
       "4                 0                0                 0                 0   \n",
       "\n",
       "   sub_team_Team 22  sub_team_Team 23  sub_team_Team 24  sub_team_Team 3  \\\n",
       "0                 0                 0                 0                0   \n",
       "1                 0                 0                 0                0   \n",
       "2                 0                 0                 0                0   \n",
       "3                 0                 0                 0                0   \n",
       "4                 0                 0                 1                0   \n",
       "\n",
       "   sub_team_Team 4  sub_team_Team 5  sub_team_Team 6  sub_team_Team 7  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                1                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   sub_team_Team 8  sub_team_Team 9  sub_team_unassigned  sub_role_Laborer  \\\n",
       "0                0                0                    0                 1   \n",
       "1                0                0                    0                 1   \n",
       "2                0                0                    0                 1   \n",
       "3                0                0                    0                 1   \n",
       "4                0                0                    0                 1   \n",
       "\n",
       "   sub_role_Shift Manager  sub_role_Team Leader  sub_workstyle_h_Group A  \\\n",
       "0                       0                     0                        0   \n",
       "1                       0                     0                        0   \n",
       "2                       0                     0                        1   \n",
       "3                       0                     0                        0   \n",
       "4                       0                     0                        0   \n",
       "\n",
       "   sub_workstyle_h_Group B  sub_workstyle_h_Group C  sub_workstyle_h_Group D  \\\n",
       "0                        0                        0                        1   \n",
       "1                        0                        1                        0   \n",
       "2                        0                        0                        0   \n",
       "3                        1                        0                        0   \n",
       "4                        0                        1                        0   \n",
       "\n",
       "   sub_workstyle_h_Group E  sup_sex_F  sup_sex_M  sup_role_Shift Manager  \\\n",
       "0                        0          1          0                       0   \n",
       "1                        0          0          1                       0   \n",
       "2                        0          0          1                       0   \n",
       "3                        0          1          0                       0   \n",
       "4                        0          1          0                       0   \n",
       "\n",
       "   sup_role_Team Leader  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c5061b",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133522bb",
   "metadata": {},
   "source": [
    "### Baseline model without weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b8a4aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "lr = LogisticRegression(solver = 'liblinear', max_iter = 500)\n",
    "\n",
    "# fit and predict \n",
    "lr.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predict test values\n",
    "y_pred_test = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e54defc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGwCAYAAABfKeoBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABC3ElEQVR4nO3deVyVdfr/8ffBhQMouLMobpO5Lyhq2iKWG4VjXx+ljfZzSS01NbJGLUowE0YnydTRDCex0mmbXEdNLbXFnFzATBlsEpVKwiYSVxC4f384nukI5rk5h+V4Xk8e9yO57899n+vGk15e1+f+HIthGIYAAABwQ14VHQAAAIC7IHECAABwEIkTAACAg0icAAAAHETiBAAA4CASJwAAAAeROAEAADioakUHgMqjqKhIP/zwg2rWrCmLxVLR4QAATDAMQ2fPnlVISIi8vMquLnLp0iXl5+c7fZ3q1avLarW6IKLyReIEmx9++EGhoaEVHQYAwAmZmZlq1KhRmVz70qVL8gnwk/KLnL5WUFCQMjIy3C55InGCTc2aNa/84o5AqSpdXNycfvzgQEWHAJSJs7lndUvTW//3Z3kZyM/Pv5I03REkVXWiM1FgKOuzLOXn55M4wX3Z2nNVvUiccNPy9/ev6BCAMlUuUy2qOfn3hMX5ilVFIXECAADmeMm5x8vc+N/mJE4AAMAci+XK5sz5bsqNcz4AAIDyRcUJAACY575FI6eQOAEAAHNo1QEAAOBGqDgBAABzeKoOAADAQbTqAAAAcCNUnAAAgDkWOfdUnfsWnEicAACASV6WK5sz57spWnUAAAAOouIEAADMoVUHAADgIA9+qo7ECQAAmOPBFSfmOAEAADiIihMAADDHg5+qI3ECAADm0KoDAADAjVBxAgAA5vBUHQAAgIM8eI4TrToAAAAHUXECAADmePDkcBInAABgjkVOznFyWSTljlYdAACAg6g4AQAA89y4auQMEicAAGAOT9UBAAA4yOKCzaRPPvlEAwcOVEhIiCwWi9auXWs7dvnyZU2fPl3t27eXn5+fQkJCNGLECP3www9218jLy9PkyZNVr149+fn56fe//72+++47U3GQOAEAgErv/Pnz6tixoxYvXlzs2IULF3TgwAE9//zzOnDggD744AMdPXpUv//97+3GRUdHa82aNXr77bf12Wef6dy5c4qKilJhYaHDcdCqAwAA5lTAyuGRkZGKjIws8VhAQIC2bdtmt2/RokXq1q2bTp48qcaNG+vMmTP661//qjfffFN9+vSRJL311lsKDQ3V9u3b1b9/f4fioOIEAADM8XLBJik3N9duy8vLc1mIZ86ckcViUa1atSRJ+/fv1+XLl9WvXz/bmJCQELVr1067d+92+LokTgAAoEKEhoYqICDAtiUkJLjkupcuXdKMGTM0bNgw+fv7S5KysrJUvXp11a5d225sYGCgsrKyHL42rToAAGCOi1p1mZmZtsRGkry9vZ2NTJcvX9ZDDz2koqIiLVmy5IbjDcOQxcS9UHECAADmuOipOn9/f7vN2cTp8uXLGjJkiDIyMrRt2za7pCwoKEj5+fnKycmxOyc7O1uBgYEOvwaJEwAAcHtXk6ZvvvlG27dvV926de2Od+nSRdWqVbObRH7q1Cl9/fXX6tmzp8OvQ6sOAACYUwFP1Z07d07//ve/bd9nZGQoNTVVderUUUhIiB544AEdOHBAGzduVGFhoW3eUp06dVS9enUFBARozJgxeuqpp1S3bl3VqVNHTz/9tNq3b297ys4RJE4AAMCcXz0ZV+rzTdq3b5969+5t+37q1KmSpJEjRyouLk7r16+XJHXq1MnuvB07digiIkKS9PLLL6tq1aoaMmSILl68qHvuuUfJycmqUqWKw3GQOAEAgEovIiJChmFc9/hvHbvKarVq0aJFWrRoUanjIHECAADmVECrrrIgcQIAAOaU8vPm7M53UyROAADAHC/Llc2Z890UyxEAAAA4iIoTAAAwhzlOAAAADvLgOU606gAAABxExQkAAJhkMfXBuNcy3LjkROIEAABMsVicS5xksejGy1VWTrTqAAAAHETFCQAAmOLsQ3WyyG0rTiROAADAFC8nW3WGxaIiF8ZTnmjVAQAAOIiKEwAAMMUVk8PdFYkTAAAwhcQJAADAQZ6cODHHCQAAwEFUnAAAgCmuWI7AXZE4AQAAU2jVAQAA4IaoOAEAAFM8ueJE4gQAAEyx/PfLmSu4K1p1AAAADqLiBAAATKFVBwAA4CBPXo6AVh0AAICDqDgBAABTvCxyqlVnuHHFicQJAACYwhwnAAAAB3ly4sQcJwAAAAdRcQIAAOY4+VQdc5wAAIDHcLZV51Sbr4LRqgMAAHAQFScAAGCKJ1ecSJwAAIApFjmZOLnx0uG06gAAABxExQkAAJhCqw4AAMBBzn7IrxvnTbTqAAAAHEXFCQAAmEKrDgAAwEEkTgAAAA7ysljk5aGTnJjjBAAA4CAqTgAAwBRPfqqOxAkAAJjiyXOcaNUBAIBK75NPPtHAgQMVEhIii8WitWvX2h03DENxcXEKCQmRj4+PIiIidPjwYbsxeXl5mjx5surVqyc/Pz/9/ve/13fffWcqDhInwIVubxeu9+Ne1bFVn+rilqMa2KOP3fGYhycrNWmLflqbqh/e26t/JCSra8sOtuO1awQoccLzOrh8i/6z9qCOvrFT8yc8J3/fGuV9K4BTlm1YpVYj71atge3Uc9L/6bOv91Z0SHAhiwu+zDp//rw6duyoxYsXl3h83rx5SkxM1OLFi7V3714FBQWpb9++Onv2rG1MdHS01qxZo7ffflufffaZzp07p6ioKBUWFjoch9skTiVll792/PhxWSwWpaamlltMZelG94vKyc/qq0MZ/9KTS2aXePzf32XoySUvKHz8QN3z9B904sfvtSF+heoF1JYkBddtoOC6DfRM0lyFT4jSuPkz1LfLnXr1yfjyvA3AKe/t+of+uCxe0x8arz1/Waue7cJ1/3PjdDL7h4oODS5ytVXnzGZWZGSkXnzxRQ0ePLjYMcMwtGDBAsXExGjw4MFq166dVq5cqQsXLmj16tWSpDNnzuivf/2r5s+frz59+igsLExvvfWWDh06pO3btzscR4UmTqNGjbL9AKtVq6bAwED17dtXr7/+uoqKiuzGnjp1SpGRkS59/eTkZEVERNjFc//995uKu2rVqmrcuLEmTJignJwcl8VWFveLsrd13yeatXKB1n2+tcTj7+zcqB0pu3U8K1NpJ/6t6a/FK8Cvpto1ayVJOnLiG/3hxcna9M8dyjiVqV0H9yhu5cu6t/vdquJVpTxvBSi1hR+s0Kj+D2h05BC1anyLXhofo0b1g5S0cXVFh4ZKJjc3127Ly8sr1XUyMjKUlZWlfv362fZ5e3urV69e2r17tyRp//79unz5st2YkJAQtWvXzjbGERVecRowYIBOnTql48ePa/Pmzerdu7eeeOIJRUVFqaCgwDYuKChI3t7eFRipvV/HvXz5cm3YsEETJ0502fUr2/3C9apVraYxkUP1y7lcHTr2r+uO8/erqdwL51RY5HgpGago+ZfzlfLNYd3T+Xa7/fd0vkN70lIqKCq4mqsqTqGhoQoICLBtCQkJpYonKytLkhQYGGi3PzAw0HYsKytL1atXV+3ata87xhEVnjh5e3srKChIDRs2VOfOnfXss89q3bp12rx5s5KTk23jrm1dffnllwoLC5PValV4eLhSUuz/h9y5c6csFos++ugjhYeHy9fXVz179lR6enqJccTFxWnlypVat26d7Td1586dN4y7UaNG6tevn4YOHaqtW+2rDCtWrFDr1q1ltVrVqlUrLVmyxHYsPz9fkyZNUnBwsKxWq5o2bWr3hrn2fnfv3q1OnTrZ7nft2rV2rUmz94uKE9ktQqfXpOiX9Yc0+f9GK+rZ0fpPbsnVyjo1a+mZP0zUXze/Xc5RAqXzU26OCosK1aB2Pbv9gbXr6seff6qgqOBqV5cjcGaTpMzMTJ05c8a2PfPMM07GZd8CNAzjhm1BR8b8WoUnTiW5++671bFjR33wwQclHj9//ryioqLUsmVL7d+/X3FxcXr66adLHBsTE6P58+dr3759qlq1qh555JESxz399NMaMmSIrZJ06tQp9ezZ06F4jx07pi1btqhatWq2fUlJSYqJidGcOXOUlpam+Ph4Pf/881q5cqUkaeHChVq/fr3effddpaen66233lLTpk1LvP7Zs2c1cOBAtW/fXgcOHNDs2bM1ffp0p+5XuvJ0wbVlUpS9XQf/qe4TB6n31KHauv8TvfXsAtUPqFNsXE1fP6154TWlnfxWc94qeTIkUFldO/nXMNx77R6UDX9/f7uttJ2WoKAgSSpWOcrOzrZVoYKCgpSfn19sWs2vxzii0q7j1KpVK3311VclHlu1apUKCwv1+uuvy9fXV23bttV3332nCRMmFBs7Z84c9erVS5I0Y8YM3Xfffbp06ZKsVqtGjRqlUaNGSZJq1KghHx8f5eXl2X4DfsvGjRtVo0YNFRYW6tKlS5KkxMRE2/HZs2dr/vz5tklszZo105EjR7Rs2TKNHDlSJ0+eVIsWLXTHHXfIYrGoSZMm132tVatWyWKxKCkpSVarVW3atNH333+vcePGmbrfayUkJGjWrFk3vFe41oW8izp26qSOnTqpL/91UIf+ulUjBzyol95ZZhtTw8dP61/8q85duqChL0xUQWHBb1wRqDzq+ddWFa8q+jHntN3+7F/+U6wKBfdV2dZxatasmYKCgrRt2zaFhYVJutLZ2bVrl+bOnStJ6tKli6pVq6Zt27ZpyJAhkq7MJ/766681b948h1+rUlacpN8unaWlpaljx47y9fW17evRo0eJYzt0+N+j3sHBwZKuZJfO6t27t1JTU/XPf/5TkydPVv/+/TV58mRJ0unTp5WZmakxY8aoRo0atu3FF1/Ut99+K+nKBPPU1FS1bNlSU6ZMKdbm+7X09HR16NDBLvnp1q2b0/f7zDPP2JVIMzMzzf0Q4BIWi0Xe1arbvq/p66eN8a8rv+CyHogbr7zL+RUYHWBO9WrVFdairT5OsZ9s+3HK57qtdVgFRQVXq4in6s6dO6fU1FTbFJWMjAylpqbq5MmTslgsio6OVnx8vNasWaOvv/5ao0aNkq+vr4YNGyZJCggI0JgxY/TUU0/po48+UkpKih5++GG1b99effr0+Y1XtldpK05paWlq1qxZiccMw3D4Or9un139jbr2ib3S8PPz0y233CLpStutd+/emjVrlmbPnm27flJSkrp37253XpUqV56M6ty5szIyMrR582Zt375dQ4YMUZ8+ffT+++8Xe62Sksjr/QzM3K+3tzcT0F3Mz+qr34X8r3rYNKiROjRvrZyzv+g/ub9o+h8m6B97PlLWz6dVx7+WHo0arob1gvTBp5slXak0bZyzQj5Wq0bPe1r+vjVsazidPvOzS967QFmbMni0xvx5mjq3aKfurTvpr5vfVWb2KY297w8VHRpcxcmKU2n6tvv27VPv3r1t30+dOlWSNHLkSCUnJ2vatGm6ePGiJk6cqJycHHXv3l1bt25VzZo1bee8/PLLqlq1qoYMGaKLFy/qnnvuUXJysu3vZkdUysTp448/1qFDh/Tkk0+WeLxNmzZ68803dfHiRfn4+EiS9uzZ4/TrVq9e3dQiWL8WGxuryMhITZgwQSEhIWrYsKGOHTum4cOHX/ccf39/DR06VEOHDtUDDzygAQMG6Oeff1adOvbzXVq1aqVVq1YpLy/Plujs27evVHGibHW+tZ22znvL9v28x56VJL257QNNXjhTLUOb6+E+/6e6/rX189kc7Tt6SH2eHqa0E/+WJIW1aKturTtJko6s+Mju2i1H9tbJH78vnxsBnPBgr/v0c+4vil/1F2XlZKttk1u1dnaSmgQ2rOjQ4MYiIiJ+s3BisVgUFxenuLi4646xWq1atGiRFi1aVOo4KjxxysvLU1ZWlgoLC/Xjjz9qy5YtSkhIUFRUlEaMGFHiOcOGDVNMTIzGjBmj5557TsePH9dLL73kdCxNmzbVhx9+qPT0dNWtW1cBAQF2FZzfEhERobZt2yo+Pl6LFy9WXFycpkyZIn9/f0VGRiovL0/79u1TTk6Opk6dqpdfflnBwcHq1KmTvLy89N577ykoKEi1atW67v0++uijmjFjhk6ePGm7X3f+vJ+b0adffSmfAbde9/hDsyc5dT7gLh4bOFyPDbz+Pxzh3jz5Q34rfI7Tli1bFBwcrKZNm2rAgAHasWOHFi5cqHXr1l23dFajRg1t2LBBR44cUVhYmGJiYmyTv5wxbtw4tWzZUuHh4apfv74+//xzU+dPnTpVSUlJyszM1NixY7V8+XIlJyerffv26tWrl5KTk23txxo1amju3LkKDw9X165ddfz4cW3atEleXsV/S/z9/bVhwwalpqaqU6dOiomJ0cyZMyWpxEnfAACUpYqY41RZWAwzE4ZQaaxatUqjR4/WmTNnbO1KZ+Xm5iogIECKCJaqVnhODZSJi1uOVnQIQJnIzc1VYJ1gnTlzRv7+/mX2GgEBAboloY+qWEvftCq8VKB/P7O9TGMtKxXeqoNj3njjDTVv3lwNGzbUwYMHNX36dA0ZMsRlSRMAAI660qpzZjkCFwZTzkic3ERWVpZmzpyprKwsBQcH68EHH9ScOXMqOiwAgAeqbOs4lScSJzcxbdo0TZs2raLDAADAo5E4AQAAUyxy8qk6l0VS/kicAACAKZ7cquPRKQAAAAdRcQIAAKZ4csWJxAkAAJhC4gQAAOAgPnIFAAAAN0TFCQAAmEKrDgAAwFEe3KujVQcAAOAgKk4AAMAUWnUAAAAO8uBOHa06AAAAR1FxAgAAptCqAwAAcJAnJ0606gAAABxExQkAAJjiyRUnEicAAGCKJz9VR+IEAABM8eSKE3OcAAAAHETFCQAAmONkxcmde3UkTgAAwBRadQAAALghKk4AAMAUT644kTgBAABTPHk5Alp1AAAADqLiBAAATLHIyVad3LfkROIEAABM8eQ5TrTqAAAAHETFCQAAmOLJFScSJwAAYIonP1VH4gQAAEzx5IoTc5wAAAAcRMUJAACYY5GTvTqXRVLuSJwAAIAptOoAAABwQ1ScAACAKV6WK5sz57srEicAAGAKrToAAADcEIkTAAAwxcticXozo6CgQM8995yaNWsmHx8fNW/eXC+88IKKiopsYwzDUFxcnEJCQuTj46OIiAgdPnzY1bdO4gQAAMy52qpzZjNj7ty5evXVV7V48WKlpaVp3rx5+vOf/6xFixbZxsybN0+JiYlavHix9u7dq6CgIPXt21dnz5516b0zxwkAAJjiJecqL2bP/eKLLzRo0CDdd999kqSmTZvqb3/7m/bt2yfpSrVpwYIFiomJ0eDBgyVJK1euVGBgoFavXq3HHnvMiWidix0AAMAlcnNz7ba8vLwSx91xxx366KOPdPToUUnSwYMH9dlnn+nee++VJGVkZCgrK0v9+vWznePt7a1evXpp9+7dLo2ZihMAADDFUop5SteeL0mhoaF2+2NjYxUXF1ds/PTp03XmzBm1atVKVapUUWFhoebMmaM//OEPkqSsrCxJUmBgoN15gYGBOnHiRKnjLAmJEwAAMMVVyxFkZmbK39/ftt/b27vE8e+8847eeustrV69Wm3btlVqaqqio6MVEhKikSNHFrvuVYZhuHzpAxInAABQIfz9/e0Sp+v54x//qBkzZuihhx6SJLVv314nTpxQQkKCRo4cqaCgIElXKk/BwcG287Kzs4tVoZzFHCcAAGBKeS9HcOHCBXl52acsVapUsS1H0KxZMwUFBWnbtm224/n5+dq1a5d69uzp/A3/ChUnAABgSnmvHD5w4EDNmTNHjRs3Vtu2bZWSkqLExEQ98sgjtutFR0crPj5eLVq0UIsWLRQfHy9fX18NGzas1HGWhMQJAABUaosWLdLzzz+viRMnKjs7WyEhIXrsscc0c+ZM25hp06bp4sWLmjhxonJyctS9e3dt3bpVNWvWdGksFsMwDJdeEW4rNzdXAQEBUkSwVJUuLm5OF7ccregQgDKRm5urwDrBOnPmjEPzhkr7GgEBAbrv7RGq5lu91Ne5fCFf/3jojTKNtaxQcQIAAKaUZp7Stee7K4cSp4ULFzp8wSlTppQ6GAAAgMrMocTp5ZdfduhiFouFxAkAgJtceU8Or0wcSpwyMjLKOg4AAOAmPLlVV+oZwPn5+UpPT1dBQYEr4wEAAJWcxQWbuzKdOF24cEFjxoyRr6+v2rZtq5MnT0q6MrfpT3/6k8sDBAAAqCxMJ07PPPOMDh48qJ07d8pqtdr29+nTR++8845LgwMAAJVPea8cXpmYXo5g7dq1euedd3TbbbfZTe5q06aNvv32W5cGBwAAKh8vOTnHyY2bdaYrTqdPn1aDBg2K7T9//rxbz5IHAAC4EdOJU9euXfWPf/zD9v3VZCkpKUk9evRwXWQAAKBSurocgTObuzLdqktISNCAAQN05MgRFRQU6JVXXtHhw4f1xRdfaNeuXWURIwAAqEQsTs5TcufEyXTFqWfPnvr888914cIF/e53v9PWrVsVGBioL774Ql26dCmLGAEAACqFUn1WXfv27bVy5UpXxwIAANyAs2sxuW+9qZSJU2FhodasWaO0tDRZLBa1bt1agwYNUtWqfGYwAAA3O09eOdx0pvP1119r0KBBysrKUsuWLSVJR48eVf369bV+/Xq1b9/e5UECAABUBqbnOI0dO1Zt27bVd999pwMHDujAgQPKzMxUhw4d9Oijj5ZFjAAAoBJhAUwTDh48qH379ql27dq2fbVr19acOXPUtWtXlwYHAAAqH4vFuSfj3DhvMl9xatmypX788cdi+7Ozs3XLLbe4JCgAAFB5eXLFyaHEKTc317bFx8drypQpev/99/Xdd9/pu+++0/vvv6/o6GjNnTu3rOMFAACoMA616mrVqmVXkjMMQ0OGDLHtMwxDkjRw4EAVFhaWQZgAAKCyYDmCG9ixY0dZxwEAANwEyxHcQK9evco6DgAAgEqv1CtWXrhwQSdPnlR+fr7d/g4dOjgdFAAAqLyoOJlw+vRpjR49Wps3by7xOHOcAAC4uVksFieXI3DfxMn0cgTR0dHKycnRnj175OPjoy1btmjlypVq0aKF1q9fXxYxAgAAVAqmK04ff/yx1q1bp65du8rLy0tNmjRR37595e/vr4SEBN13331lEScAAKgkvFSKyss157sr07GfP39eDRo0kCTVqVNHp0+fliS1b99eBw4ccG10AACg8vlvq660mzsvHV6qlcPT09MlSZ06ddKyZcv0/fff69VXX1VwcLDLAwQAAKgsTLfqoqOjderUKUlSbGys+vfvr1WrVql69epKTk52dXwAAKCS4ak6E4YPH277dVhYmI4fP65//etfaty4serVq+fS4AAAQOVD4uQEX19fde7c2RWxAAAAN+DJyxE4lDhNnTrV4QsmJiaWOhgAAIDKzKHEKSUlxaGLuXMGif/JfH+P/P39KzoMAEAl5SWLvJz4qF5nzq1ofMgvAAAwxZNbde68BhUAAEC5cnpyOAAA8Cw8VQcAAOAgy3+/nDnfXdGqAwAAcBAVJwAAYAqTw0168803dfvttyskJEQnTpyQJC1YsEDr1q1zaXAAAKDyuTrHyZnNXZlOnJYuXaqpU6fq3nvv1S+//KLCwkJJUq1atbRgwQJXxwcAAFBpmE6cFi1apKSkJMXExKhKlSq2/eHh4Tp06JBLgwMAAJWPxbYEZuk3d2V6jlNGRobCwsKK7ff29tb58+ddEhQAAKi8vOTkcgSe9FRds2bNlJqaWmz/5s2b1aZNG1fEBAAAKjPL/yaIl2Zz47zJfMXpj3/8ox5//HFdunRJhmHoyy+/1N/+9jclJCRo+fLlZREjAABApWC64jR69GjFxsZq2rRpunDhgoYNG6ZXX31Vr7zyih566KGyiBEAAFQiFhd8mfX999/r4YcfVt26deXr66tOnTpp//79tuOGYSguLk4hISHy8fFRRESEDh8+7MrbllTKdZzGjRuncePG6aefflJRUZEaNGjg6rgAAEAlVd4fuZKTk6Pbb79dvXv31ubNm9WgQQN9++23qlWrlm3MvHnzlJiYqOTkZN1666168cUX1bdvX6Wnp6tmzZqljvVaTi2AWa9ePVfFAQAAUKK5c+cqNDRUK1assO1r2rSp7deGYWjBggWKiYnR4MGDJUkrV65UYGCgVq9erccee8xlsZhOnJo1a/abK34eO3bMqYAAAEDl5qqVw3Nzc+32e3t7y9vbu9j49evXq3///nrwwQe1a9cuNWzYUBMnTtS4ceMkXXniPysrS/369bO7Vq9evbR79+6KTZyio6Ptvr98+bJSUlK0ZcsW/fGPf3RVXAAAoJLy+u+XM+dLUmhoqN3+2NhYxcXFFRt/7Ngx2wLczz77rL788ktNmTJF3t7eGjFihLKysiRJgYGBducFBgbaPuHEVUwnTk888USJ+//yl79o3759TgcEAAA8Q2Zmpvz9/W3fl1RtkqSioiKFh4crPj5ekhQWFqbDhw9r6dKlGjFihG3ctVUwwzBc/rl4Llu6MzIyUn//+99ddTkAAFBJObOG06/bfP7+/nbb9RKn4ODgYmtFtm7dWidPnpQkBQUFSZKt8nRVdnZ2sSqUs1yWOL3//vuqU6eOqy4HAAAqKVclTo66/fbblZ6ebrfv6NGjatKkiaQr86+DgoK0bds22/H8/Hzt2rVLPXv2dP6Gf8V0qy4sLMzuhg3DUFZWlk6fPq0lS5a4NDgAAIAnn3xSPXv2VHx8vIYMGaIvv/xSr732ml577TVJVxK56OhoxcfHq0WLFmrRooXi4+Pl6+urYcOGuTQW04nT/fffb/e9l5eX6tevr4iICLVq1cpVcQEAgErq6kf1OnO+GV27dtWaNWv0zDPP6IUXXlCzZs20YMECDR8+3DZm2rRpunjxoiZOnKicnBx1795dW7dudekaTpLJxKmgoEBNmzZV//79bf1EAADgWVy1HIEZUVFRioqK+s1rxsXFlfhUniuZmuNUtWpVTZgwQXl5eWUVDwAAqOSurhzuzOauTE8O7969u1JSUsoiFgAAgErN9ByniRMn6qmnntJ3332nLl26yM/Pz+54hw4dXBYcAACofEr7Qb2/Pt9dOZw4PfLII1qwYIGGDh0qSZoyZYrtmMVisS0yVVhY6PooAQBApeFl8ZKXxYmVw504t6I5nDitXLlSf/rTn5SRkVGW8QAAAFRaDidOhmFIkm2xKQAA4Jkq4qm6ysLUHCd3vlEAAOAqzs1xkifMcZKkW2+99YbJ088//+xUQAAAAJWVqcRp1qxZCggIKKtYAACAG3B2LSZ3XsfJVOL00EMPqUGDBmUVCwAAcAOevByBw88DMr8JAAB4OtNP1QEAAM/mZXGu3eblxrUYhxOnoqKisowDAAC4CYvFSxYnFrF05tyKZvojVwAAgGdjjhMAAABuiIoTAAAwheUIAAAAHOTJH7lCqw4AAMBBVJwAAIApXrLIy4kJ3s6cW9FInAAAgCm06gAAAHBDVJwAAIApLIAJAADgIE+e4+S+KR8AAEA5o+IEAABM8eTJ4SROAADAJOc+q05u3KojcQIAAKZY5GTFyY0TJ+Y4AQAAOIiKEwAAMMWTn6ojcQIAAKZ48jpO7hs5AABAOaPiBAAATLE4+VSdO08OJ3ECAACmWCzOrcXkxss40aoDAABwFBUnAABgCq06AAAAB3nyR67QqgMAAHAQFScAAGAKC2ACAAA4yJNbdSROAADAFMt/a07OnO+u3DdyAACAckbFCQAAmEKrDgAAwEGevI4TrToAAAAHUXECAACmeFks8nKi3ebMuRWNihMAADDF4oIvZyQkJMhisSg6Otq2zzAMxcXFKSQkRD4+PoqIiNDhw4edvNPiSJwAAIDb2Lt3r1577TV16NDBbv+8efOUmJioxYsXa+/evQoKClLfvn119uxZl74+iRMAADDl6lN1zmylce7cOQ0fPlxJSUmqXbu2bb9hGFqwYIFiYmI0ePBgtWvXTitXrtSFCxe0evVqV922JBInAABg2tUPXSnddjX9yM3Ntdvy8vJ+81Uff/xx3XffferTp4/d/oyMDGVlZalfv362fd7e3urVq5d2797t4jsHAACoAKGhoQoICLBtCQkJ1x379ttv68CBAyWOycrKkiQFBgba7Q8MDLQdcxWeqgMAAKa4agHMzMxM+fv72/Z7e3uXOD4zM1NPPPGEtm7dKqvVesPrXmUYhssX2yRxAgAAplxtujlzviT5+/vbJU7Xs3//fmVnZ6tLly62fYWFhfrkk0+0ePFipaenS7pSeQoODraNyc7OLlaFchatOgAAYEp5Tw6/5557dOjQIaWmptq28PBwDR8+XKmpqWrevLmCgoK0bds22zn5+fnatWuXevbs6dJ7p+IEAAAqtZo1a6pdu3Z2+/z8/FS3bl3b/ujoaMXHx6tFixZq0aKF4uPj5evrq2HDhrk0FhInAABgSmX8rLpp06bp4sWLmjhxonJyctS9e3dt3bpVNWvWdOnrkDgBAABTXDU53Bk7d+4sds24uDjFxcU5fe3fwhwnAAAAB1FxAgAAplxp1JW+9lIWrbryQuIEAABM8bJY5OVEu82ZcysarToAAAAHUXECAACmVMan6soLiRMAADClMjxVV1Fo1QEAADiIxAkoZwlv/UUB97az21oM71XRYQEutWzDKrUaebdqDWynnpP+T599vbeiQ4ILWVzw5a5InFzMYrFo7dq1FR2GpMoVC+y1bnKLjr6107Z9sWRNRYcEuMx7u/6hPy6L1/SHxmvPX9aqZ7tw3f/cOJ3M/qGiQ4OLlPdn1VUmHpc4jRo1yvabVrVqVTVu3FgTJkxQTk6OS65/6tQpRUZGuuRauHlVrVJFgXXq2bZ6AXUqOiTAZRZ+sEKj+j+g0ZFD1KrxLXppfIwa1Q9S0sbVFR0aXMTLBV/uyn0jd8KAAQN06tQpHT9+XMuXL9eGDRs0ceJEl1w7KChI3t7eLrkWbl7ffn9SLR/urfaj+2v0n55WxqnMig4JcIn8y/lK+eaw7ul8u93+ezrfoT1pKRUUFeA6Hpk4eXt7KygoSI0aNVK/fv00dOhQbd261XZ8xYoVat26taxWq1q1aqUlS5bYjuXn52vSpEkKDg6W1WpV06ZNlZCQYDt+bXts9+7d6tSpk6xWq8LDw7V27VpZLBalpqZKuvJZOxaLRR999JHCw8Pl6+urnj17Kj093S7mDRs2qEuXLrJarWrevLlmzZqlgoIC2/FvvvlGd911l6xWq9q0aaNt27bd8OeQl5en3Nxcuw1lL7xlB736VLw+mL1MC6fEKTvnJ/V7+mH9nPtLRYcGOO2n3BwVFhWqQe16dvsDa9fVjz//VEFRwdU8uVXn8csRHDt2TFu2bFG1atUkSUlJSYqNjdXixYsVFhamlJQUjRs3Tn5+fho5cqQWLlyo9evX691331Xjxo2VmZmpzMySqwVnz57VwIEDde+992r16tU6ceKEoqOjSxwbExOj+fPnq379+ho/frweeeQRff7555KkDz/8UA8//LAWLlyoO++8U99++60effRRSVJsbKyKioo0ePBg1atXT3v27FFubu51X+fXEhISNGvWLPM/NDilb9c7bb9uK6lb647qNCZSq7ev06TBIysuMMCFrp38axiSG/9diWuwjpOH2bhxo2rUqKHCwkJdunRJkpSYmChJmj17tubPn6/BgwdLkpo1a6YjR45o2bJlGjlypE6ePKkWLVrojjvukMViUZMmTa77OqtWrZLFYlFSUpKtEvT9999r3LhxxcbOmTNHvXpdebJqxowZuu+++3Tp0iVZrVbNmTNHM2bM0MiRV/5Sbd68uWbPnq1p06YpNjZW27dvV1pamo4fP65GjRpJkuLj42841+qZZ57R1KlTbd/n5uYqNDTU0R8jXMTP6qs2TVro2x9OVHQogNPq+ddWFa8q+jHntN3+7F/+U6wKBbgjj0ycevfuraVLl+rChQtavny5jh49qsmTJ+v06dPKzMzUmDFj7JKbgoICBQQESLoyubxv375q2bKlBgwYoKioKPXr16/E10lPT1eHDh1ktVpt+7p161bi2A4dOth+HRwcLEnKzs5W48aNtX//fu3du1dz5syxjbma9F24cEFpaWlq3LixLWmSpB49etzw5+Dt7c18rEog73K+jmZmqGe7LhUdCuC06tWqK6xFW32csluDbv/fn40fp3yuqNvuqcDI4FLOttvcuPzokYmTn5+fbrnlFknSwoUL1bt3b82aNUuTJk2SdKVd1717d7tzqlSpIknq3LmzMjIytHnzZm3fvl1DhgxRnz599P777xd7HcMwir2xDMMoMaarrULpfyuqFhUV2f47a9YsWxXs16xWa4nXdOf+8c0uZvmfFdk9Qo3qB+unX37Wn99eprMXzukP9wyq6NAAl5gyeLTG/HmaOrdop+6tO+mvm99VZvYpjb3vDxUdGlyEVp2Hi42NVWRkpCZMmKCGDRvq2LFjGj58+HXH+/v7a+jQoRo6dKgeeOABDRgwQD///LPq1LF/pLxVq1ZatWqV8vLybJWdffv2mY6vc+fOSk9PtyV712rTpo1OnjypH374QSEhIZKkL774wvTroHz88NOPGjN3mv6Tm6N6AXUU3rKDtr+8Wo0DQyo6NMAlHux1n37O/UXxq/6irJxstW1yq9bOTlKTwIYVHRrgNBInSREREWrbtq3i4+MVFxenKVOmyN/fX5GRkcrLy9O+ffuUk5OjqVOn6uWXX1ZwcLA6deokLy8vvffeewoKClKtWrWKXXfYsGGKiYnRo48+qhkzZujkyZN66aWXJJmrCM2cOVNRUVEKDQ3Vgw8+KC8vL3311Vc6dOiQXnzxRfXp00ctW7bUiBEjNH/+fOXm5iomJsZVPx642IoZL1V0CECZe2zgcD028Pr/AIV78+SKk0cuR1CSqVOnKikpSf3799fy5cuVnJys9u3bq1evXkpOTlazZs0kSTVq1NDcuXMVHh6url276vjx49q0aZO8vIr/KP39/bVhwwalpqaqU6dOiomJ0cyZMyXJbt7TjfTv318bN27Utm3b1LVrV912221KTEy0TUz38vLSmjVrlJeXp27dumns2LF286EAAHApi8X5zU1ZjOtNukGZWLVqlUaPHq0zZ87Ix8enosOxk5ubq4CAAGX+dEL+/v4VHQ5QJqp7Va/oEIAykZubq8A6wTpz5kyZ/Rl+9e+JHce2qkZNv1Jf59zZ8+rdvF+ZxlpWaNWVsTfeeEPNmzdXw4YNdfDgQU2fPl1DhgypdEkTAACO8uRWHYlTGcvKytLMmTOVlZWl4OBgPfjgg7TRAABuzdnVv935yW8SpzI2bdo0TZs2raLDAADAZTy54sTkcAAAAAdRcQIAAKZY5FzVyH3rTSROAADAJIucnOPkxqkTrToAAAAHUXECAACmePLkcBInAABgiicnTrTqAAAAHETFCQAAmMICmAAAAA6iVQcAAIAbouIEAABMoVUHAADgIE9u1ZE4AQAAUzw5cWKOEwAAgIOoOAEAAFOY4wQAAOAgWnUAAAC4ISpOAADAFE+uOJE4AQAAc5yc4yQ3nuNEqw4AAMBBVJwAAIBJlv9uzpzvnkicAACAKZ68HAGtOgAAUKklJCSoa9euqlmzpho0aKD7779f6enpdmMMw1BcXJxCQkLk4+OjiIgIHT582OWxkDgBAABTLC74MmPXrl16/PHHtWfPHm3btk0FBQXq16+fzp8/bxszb948JSYmavHixdq7d6+CgoLUt29fnT171qX3TqsOAACYUt7LEWzZssXu+xUrVqhBgwbav3+/7rrrLhmGoQULFigmJkaDBw+WJK1cuVKBgYFavXq1HnvssVLHei0qTgAAwJSrc5yc2SQpNzfXbsvLy3Po9c+cOSNJqlOnjiQpIyNDWVlZ6tevn22Mt7e3evXqpd27d7v03kmcAABAhQgNDVVAQIBtS0hIuOE5hmFo6tSpuuOOO9SuXTtJUlZWliQpMDDQbmxgYKDtmKvQqgMAAKZcWYzAmVbdFZmZmfL397ft9/b2vuG5kyZN0ldffaXPPvus+HWveVrPMAyXP8FH4gQAAExx1Rwnf39/u8TpRiZPnqz169frk08+UaNGjWz7g4KCJF2pPAUHB9v2Z2dnF6tCOYtWHQAAqNQMw9CkSZP0wQcf6OOPP1azZs3sjjdr1kxBQUHatm2bbV9+fr527dqlnj17ujQWKk4AAMCU8l4A8/HHH9fq1au1bt061axZ0zZvKSAgQD4+PrJYLIqOjlZ8fLxatGihFi1aKD4+Xr6+vho2bFip4ywJiRMAADClvJcjWLp0qSQpIiLCbv+KFSs0atQoSdK0adN08eJFTZw4UTk5Oerevbu2bt2qmjVrljrOkpA4AQCASs0wjBuOsVgsiouLU1xcXJnGQuIEAABM8eTPqiNxAgAAppR3q64y4ak6AAAAB1FxAgAAJlkkp6pG7ltxInECAACmeG7aROIEAABM8uTJ4cxxAgAAcBAVJwAAYJLnNutInAAAgCmemzbRqgMAAHAYFScAAGCS59acSJwAAIApPFUHAACAGyJxAgAAcBCtOgAAYAof8gsAAIAbouIEAABMoeIEAACAG6LiBAAATGE5AgAAANwQiRMAAICDaNUBAACTnJsc7s4fuULFCQAAwEFUnAAAgEl8yC8AAIBDPDdtolUHAADgMCpOAADAFE9ex4nECQAAmOS5zTpadQAAAA6i4gQAAEzx3HoTiRMAACgVd05/So/ECQAAmOLJk8OZ4wQAAOAgEicAAAAH0aoDAACmWJz8kF/nPiC4YlFxAgAAcBAVJwAAYJLnLkhA4gQAAEzx3LSJVh0AAIDDqDgBAABTPHkdJxInAABgkuc262jVAQAAOIiKEwAAMMVz600kTgAAwDTPTZ1InAAAgCmePDmcOU4AAMAtLFmyRM2aNZPValWXLl306aeflnsMJE4AAKDSe+eddxQdHa2YmBilpKTozjvvVGRkpE6ePFmucZA4AQAAUywu+DIrMTFRY8aM0dixY9W6dWstWLBAoaGhWrp0aRnc4fUxxwk2hmFIks6ePVvBkQBlp7pX9YoOASgTZ3Ov/Nl99c/yspSb69zfE1fPz83Ntdvv7e0tb2/vYuPz8/O1f/9+zZgxw25/v379tHv3bqdiMYvECTZXE6Y2zdpVcCQAgNI6e/asAgICyuTa1atXV1BQkFo0vdXpa9WoUUOhoaF2+2JjYxUXF1ds7E8//aTCwkIFBgba7Q8MDFRWVpbTsZhB4gSbkJAQZWZmqmbNmm79xIO7yM3NVWhoqDIzM+Xv71/R4QAux3u8fBmGobNnzyokJKTMXsNqtSojI0P5+flOX8swjGJ/15RUbfq1a8eXdI2yRuIEGy8vLzVq1Kiiw/A4/v7+/KWCmxrv8fJTVpWmX7NarbJarWX+Or9Wr149ValSpVh1KTs7u1gVqqwxORwAAFRq1atXV5cuXbRt2za7/du2bVPPnj3LNRYqTgAAoNKbOnWq/t//+38KDw9Xjx499Nprr+nkyZMaP358ucZB4gRUEG9vb8XGxt6wpw+4K97jcKWhQ4fqP//5j1544QWdOnVK7dq106ZNm9SkSZNyjcNilMdziwAAADcB5jgBAAA4iMQJAADAQSROAAAADiJxgkeyWCxau3btdY8fP35cFotFqamp5RZTWbrR/QLOqEzvr8oUC25OJE64aYwaNUoWi0UWi0XVqlVTYGCg+vbtq9dff11FRUV2Y0+dOqXIyEiXvn5ycrIiIiLs4rn//vtNxV21alU1btxYEyZMUE5OjstiK4v7hfso6/cY7y94EhIn3FQGDBigU6dO6fjx49q8ebN69+6tJ554QlFRUSooKLCNCwoKqlSPSP867uXLl2vDhg2aOHGiy65f2e4X5a8s32O8v+BJSJxwU/H29lZQUJAaNmyozp0769lnn9W6deu0efNmJScn28ZdW87/8ssvFRYWJqvVqvDwcKWkpNhdd+fOnbJYLProo48UHh4uX19f9ezZU+np6SXGERcXp5UrV2rdunW2f+nv3LnzhnE3atRI/fr109ChQ7V161a7MStWrFDr1q1ltVrVqlUrLVmyxHYsPz9fkyZNUnBwsKxWq5o2baqEhITr3u/u3bvVqVMn2/2uXbvWrjVp9n5R+d3oPVYZ318bNmxQly5dZLVa1bx5c82aNcvuH0DffPON7rrrLlmtVrVp06bYqtJAWWABTNz07r77bnXs2FEffPCBxo4dW+z4+fPnFRUVpbvvvltvvfWWMjIy9MQTT5R4rZiYGM2fP1/169fX+PHj9cgjj+jzzz8vNu7pp59WWlqacnNztWLFCklSnTp1HIr32LFj2rJli6pVq2bbl5SUpNjYWC1evFhhYWFKSUnRuHHj5Ofnp5EjR2rhwoVav3693n33XTVu3FiZmZnKzMws8fpnz57VwIEDde+992r16tU6ceKEoqOjnbpfuJdr32OV8f314Ycf6uGHH9bChQt155136ttvv9Wjjz4qSYqNjVVRUZEGDx6sevXqac+ePcrNzb3u6wAuZQA3iZEjRxqDBg0q8djQoUON1q1b276XZKxZs8YwDMNYtmyZUadOHeP8+fO240uXLjUkGSkpKYZhGMaOHTsMScb27dttY/7xj38YkoyLFy+ajufacVWqVDH8/PwMq9VqSDIkGYmJibYxoaGhxurVq+3Omz17ttGjRw/DMAxj8uTJxt13320UFRWV+Bq/vt+lS5cadevWtYs7KSnJ6ftF5XWj91hlfH/deeedRnx8vN3rvPnmm0ZwcLBhGIbx4YcfGlWqVDEyMzNtxzdv3mwXC1AWqDjBIxiGIYvFUuKxtLQ0dezYUb6+vrZ9PXr0KHFshw4dbL8ODg6WdOXTuRs3buxUfL1799bSpUt14cIFLV++XEePHtXkyZMlSadPn1ZmZqbGjBmjcePG2c4pKCiwfRL6qFGj1LdvX7Vs2VIDBgxQVFSU+vXrV+Jrpaenq0OHDnafbt6tW7dyvV+Uv+u9xyrr+2v//v3au3ev5syZYxtTWFioS5cu6cKFC0pLS1Pjxo3VqFEj2/Hr/X8LuBKJEzxCWlqamjVrVuIxw8SnDv26fXY1Ebv2ib3S8PPz0y233CJJWrhwoXr37q1Zs2Zp9uzZtusnJSWpe/fududVqVJFktS5c2dlZGRo8+bN2r59u4YMGaI+ffro/fffL/ZaJSWR1/sZlNX9ovxd7z02adIkSZXv/VVUVKRZs2Zp8ODBxc6zWq0lXvN6/zgCXInECTe9jz/+WIcOHdKTTz5Z4vE2bdrozTff1MWLF+Xj4yNJ2rNnj9OvW716dRUWFpbq3NjYWEVGRmrChAkKCQlRw4YNdezYMQ0fPvy65/j7+2vo0KEaOnSoHnjgAQ0YMEA///xzsblVrVq10qpVq5SXl2d7Emrfvn2lihPu69fvscr4/urcubPS09Ntyd612rRpo5MnT+qHH35QSEiIJOmLL74w/TqAWTxVh5tKXl6esrKy9P333+vAgQOKj4/XoEGDFBUVpREjRpR4zrBhw+Tl5aUxY8boyJEj2rRpk1566SWnY2natKm++uorpaen66efftLly5cdPjciIkJt27ZVfHy8pCtP6SUkJOiVV17R0aNHdejQIa1YsUKJiYmSpJdffllvv/22/vWvf+no0aN67733FBQUpFq1apV4v0VFRXr00UeVlpamDz/80Ha//Ivdc/z6PVYZ318zZ87UG2+8obi4OB0+fFhpaWl655139Nxzz0mS+vTpo5YtW2rEiBE6ePCgPv30U8XExDj/gwFugMQJN5UtW7YoODhYTZs21YABA7Rjxw4tXLhQ69ats7UdrlWjRg1t2LBBR44cUVhYmGJiYjR37lynYxk3bpxatmyp8PBw1a9f3/TTaFOnTlVSUpIyMzM1duxYLV++XMnJyWrfvr169eql5ORkW/uxRo0amjt3rsLDw9W1a1cdP35cmzZtkpdX8f/F/f39tWHDBqWmpqpTp06KiYnRzJkzJcluXgpuflffY/37969076/+/ftr48aN2rZtm7p27arbbrtNiYmJatKkiSTJy8tLa9asUV5enrp166axY8fazYcCyorFMDPBA8BNadWqVRo9erTOnDlja1cCrsL7CzcT5jgBHuiNN95Q8+bN1bBhQx08eFDTp0/XkCFD+EsNLsH7CzczEifAA2VlZWnmzJnKyspScHCwHnzwQdoccBneX7iZ0aoDAABwEJPDAQAAHETiBAAA4CASJwAAAAeROAEAADiIxAkAAMBBJE4AKpW4uDh16tTJ9v2oUaN0//33l3scx48fl8ViUWpq6nXHNG3aVAsWLHD4msnJySV+TIlZFotFa9eudfo6AMwjcQJwQ6NGjZLFYpHFYlG1atXUvHlzPf300zp//nyZv/Yrr7yi5ORkh8Y6kuwAgDNYABOAQwYMGKAVK1bo8uXL+vTTTzV27FidP39eS5cuLTb28uXLqlatmkteNyAgwCXXAQBXoOIEwCHe3t4KCgpSaGiohg0bpuHDh9vaRVfba6+//rqaN28ub29vGYahM2fO6NFHH1WDBg3k7++vu+++WwcPHrS77p/+9CcFBgaqZs2aGjNmjC5dumR3/NpWXVFRkebOnatbbrlF3t7eaty4sW1V6qsfShsWFiaLxaKIiAjbeStWrFDr1q1ltVrVqlUrLVmyxO51vvzyS4WFhclqtSo8PFwpKSmmf0aJiYlq3769/Pz8FBoaqokTJ+rcuXPFxq1du1a33nqrrFar+vbtq8zMTLvjGzZsUJcuXWS1WtW8eXPNmjVLBQUFpuMB4HokTgBKxcfHR5cvX7Z9/+9//1vvvvuu/v73v9taZffdd5+ysrK0adMm7d+/X507d9Y999yjn3/+WZL07rvvKjY2VnPmzNG+ffsUHBxcLKG51jPPPKO5c+fq+eef15EjR7R69WoFBgZKupL8SNL27dt16tQpffDBB5KkpKQkxcTEaM6cOUpLS1N8fLyef/55rVy5UpJ0/vx5RUVFqWXLltq/f7/i4uL09NNPm/6ZeHl5aeHChfr666+1cuVKffzxx5o2bZrdmAsXLmjOnDlauXKlPv/8c+Xm5uqhhx6yHf/www/18MMPa8qUKTpy5IiWLVum5ORkPrIEqCwMALiBkSNHGoMGDbJ9/89//tOoW7euMWTIEMMwDCM2NtaoVq2akZ2dbRvz0UcfGf7+/salS5fsrvW73/3OWLZsmWEYhtGjRw9j/Pjxdse7d+9udOzYscTXzs3NNby9vY2kpKQS48zIyDAkGSkpKXb7Q0NDjdWrV9vtmz17ttGjRw/DMAxj2bJlRp06dYzz58/bji9durTEa/1akyZNjJdffvm6x999912jbt26tu9XrFhhSDL27Nlj25eWlmZIMv75z38ahmEYd955pxEfH293nTfffNMIDg62fS/JWLNmzXVfF0DZYY4TAIds3LhRNWrUUEFBgS5fvqxBgwZp0aJFtuNNmjRR/fr1bd/v379f586dU926de2uc/HiRX377beSpLS0NI0fP97ueI8ePbRjx44SY0hLS1NeXp7uueceh+M+ffq0MjMzNWbMGI0bN862v6CgwDZ/Ki0tTR07dpSvr69dHGbt2LFD8fHxOnLkiHJzc1VQUKBLly7p/Pnz8vPzkyRVrVpV4eHhtnNatWqlWrVqKS0tTd26ddP+/fu1d+9euwpTYWGhLl26pAsXLtjFCKD8kTgBcEjv3r21dOlSVatWTSEhIcUmf19NDK4qKipScHCwdu7cWexapX0k38fHx/Q5RUVFkq6067p37253rEqVKpIkwwWfdX7ixAnde++9Gj9+vGbPnq06deros88+05gxY+xamtKV5QSudXVfUVGRZs2apcGDBxcbY7VanY4TgHNInAA4xM/PT7fccovD4zt37qysrCxVrVpVTZs2LXFM69attWfPHo0YMcK2b8+ePde9ZosWLeTj46OPPvpIY8eOLXa8evXqkq5UaK4KDAxUw4YNdezYMQ0fPrzE67Zp00ZvvvmmLl68aEvOfiuOkuzbt08FBQWaP3++vLyuTB999913i40rKCjQvn371K1bN0lSenq6fvnlF7Vq1UrSlZ9benq6qZ81gPJD4gSgTPTp00c9evTQ/fffr7lz56ply5b64YcftGnTJt1///0KDw/XE088oZEjRyo8PFx33HGHVq1apcOHD6t58+YlXtNqtWr69OmaNm2aqlevrttvv12nT5/W4cOHNWbMGDVo0EA+Pj7asmWLGjVqJKvVqoCAAMXFxWnKlCny9/dXZGSk8vLytG/fPuXk5Gjq1KkaNmyYYmJiNGbMGD333HM6fvy4XnrpJVP3+7vf/U4FBQVatGiRBg4cqM8//1yvvvpqsXHVqlXT5MmTtXDhQlWrVk2TJk3SbbfdZkukZs6cqaioKIWGhurBBx+Ul5eXvvrqKx06dEgvvvii+d8IAC7FU3UAyoTFYtGmTZt011136ZFHHtGtt96qhx56SMePH7c9BTd06FDNnDlT06dPV5cuXXTixAlNmDDhN6/7/PPP66mnntLMmTPVunVrDR06VNnZ2ZKuzB9auHChli1bppCQEA0aNEiSNHbsWC1fvlzJyclq3769evXqpeTkZNvyBTVq1NCGDRt05MgRhYWFKSYmRnPnzjV1v506dVJiYqLmzp2rdu3aadWqVUpISCg2ztfXV9OnT9ewYcPUo0cP+fj46O2337Yd79+/vzZu3Kht27apa9euuu2225SYmKgmTZqYigdA2bAYrmjuAwAAeAAqTgAAAA4icQIAAHAQiRMAAICDSJwAAAAcROIEAADgIBInAAAAB5E4AQAAOIjECQAAwEEkTgAAAA4icQIAAHAQiRMAAICD/j/PQoJZXdAyPAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "display_cm = ConfusionMatrixDisplay.from_predictions(y_true=y_test, y_pred=y_pred_test, display_labels = [\"Didn't Resign\", 'Resigned'], cmap=plt.cm.Greens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4835c6ad",
   "metadata": {},
   "source": [
    "There were no true positives predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "86f48932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       132\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.48      0.50      0.49       137\n",
      "weighted avg       0.93      0.96      0.95       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kylerodriguez/miniconda3/envs/employee-attrition/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kylerodriguez/miniconda3/envs/employee-attrition/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kylerodriguez/miniconda3/envs/employee-attrition/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification report for testing data\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dd9929f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9635036496350365\n",
      "Area Under Curve: 0.5\n",
      "Confusion Matrix: \n",
      "[[132   0]\n",
      " [  5   0]]\n",
      "Recall score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_pred_test)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred_test)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_pred_test)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b3c44c",
   "metadata": {},
   "source": [
    "The metrics for the baseline model indicate that the model's performance is very poor even though there is a high accuracy score. The recall score is zero which means that there were no employees correctly classified as a resignation. Lastly, the AUC score of 0.49 indicates that the model performs no better than random guessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62bd68d",
   "metadata": {},
   "source": [
    "### Acccounting for Imbalanced Data: Weighted Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "35862794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify weight proportional to class imbalance\n",
    "w = {0:2, 1:98}\n",
    "\n",
    "# instantiate model with specified weight params\n",
    "weighted_lr = LogisticRegression(solver = 'liblinear', max_iter = 500, class_weight=w)\n",
    "\n",
    "# fit model to training data\n",
    "weighted_lr.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# predict values\n",
    "y_pred = weighted_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2d618e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9416058394160584\n",
      "Area Under Curve: 0.5848484848484848\n",
      "Confusion Matrix: \n",
      "[[128   4]\n",
      " [  4   1]]\n",
      "Recall score: 0.2\n"
     ]
    }
   ],
   "source": [
    "# Check metrics\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_pred)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881add4",
   "metadata": {},
   "source": [
    "After adding the `class_weight` attribute, there is marginal improvement in the AUC score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95be19f4",
   "metadata": {},
   "source": [
    "### Find Best Weights with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "680ffb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9017133956386292 with param: {'class_weight': {0: 0.001, 1: 1.0}}\n"
     ]
    }
   ],
   "source": [
    "# define grid of weights\n",
    "w = [{0:1000,1:100},{0:1000,1:10}, {0:1000,1:1.0}, \n",
    "     {0:500,1:1.0}, {0:400,1:1.0}, {0:300,1:1.0}, {0:200,1:1.0}, \n",
    "     {0:150,1:1.0}, {0:100,1:1.0}, {0:99,1:1.0}, {0:10,1:1.0}, \n",
    "     {0:0.01,1:1.0}, {0:0.01,1:10}, {0:0.01,1:100}, \n",
    "     {0:0.001,1:1.0}, {0:0.005,1:1.0}, {0:1.0,1:1.0}, \n",
    "     {0:1.0,1:0.1}, {0:10,1:0.1}, {0:100,1:0.1}, \n",
    "     {0:10,1:0.01}, {0:1.0,1:0.01}, {0:1.0,1:0.001}, {0:1.0,1:0.005}, \n",
    "     {0:1.0,1:10}, {0:1.0,1:99}, {0:1.0,1:100}, {0:1.0,1:150}, \n",
    "     {0:1.0,1:200}, {0:1.0,1:300},{0:1.0,1:400},{0:1.0,1:500}, \n",
    "     {0:1.0,1:1000}, {0:10,1:1000},{0:100,1:1000} ]\n",
    "\n",
    "params = {'class_weight': w}\n",
    "\n",
    "# define model\n",
    "lr3 = LogisticRegression(max_iter=500, random_state=13)\n",
    "\n",
    "# define Randomized CV\n",
    "grid = GridSearchCV(lr3, params, scoring=\"roc_auc\", n_jobs=-1, refit=True)\n",
    "\n",
    "# fit CV\n",
    "grid.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# get best score and params\n",
    "print(f'Best score: {grid.best_score_} with param: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "372c685e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.11678832116788321\n",
      "Confusion Matrix: \n",
      "[[ 11 121]\n",
      " [  0   5]]\n",
      "Area Under Curve: 0.5416666666666667\n",
      "Recall score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# check model with best weights\n",
    "w = {0: 0.001, 1: 1}\n",
    "\n",
    "# define model\n",
    "lr4 = LogisticRegression(class_weight=w, random_state=13)\n",
    "\n",
    "# fit it\n",
    "lr4.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# test\n",
    "y_pred = lr4.predict(X_test)\n",
    "\n",
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_pred)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_pred)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26f7c9b",
   "metadata": {},
   "source": [
    "Using the best params from the grid search of `class_weight` alone, the accuracy dramatically decreased, and so did the AUC score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9fcc2",
   "metadata": {},
   "source": [
    "### Hyperparam tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7f904402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9256230529595015 with param: {'C': 0.5, 'class_weight': {0: 0.01, 1: 10}, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kylerodriguez/miniconda3/envs/employee-attrition/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "13650 fits failed out of a total of 27300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "13650 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kylerodriguez/miniconda3/envs/employee-attrition/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kylerodriguez/miniconda3/envs/employee-attrition/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kylerodriguez/miniconda3/envs/employee-attrition/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 434, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got newton-cholesky.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kylerodriguez/miniconda3/envs/employee-attrition/lib/python3.10/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.76231395        nan 0.79187435 ...        nan 0.7816459         nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "w = [{0:1000,1:100},{0:1000,1:10}, {0:1000,1:1.0}, \n",
    "     {0:500,1:1.0}, {0:400,1:1.0}, {0:300,1:1.0}, {0:200,1:1.0}, \n",
    "     {0:150,1:1.0}, {0:100,1:1.0}, {0:99,1:1.0}, {0:10,1:1.0}, \n",
    "     {0:0.01,1:1.0}, {0:0.01,1:10}, {0:0.01,1:100}, \n",
    "     {0:0.001,1:1.0}, {0:0.005,1:1.0}, {0:1.0,1:1.0}, \n",
    "     {0:1.0,1:0.1}, {0:10,1:0.1}, {0:100,1:0.1}, \n",
    "     {0:10,1:0.01}, {0:1.0,1:0.01}, {0:1.0,1:0.001}, {0:1.0,1:0.005}, \n",
    "     {0:1.0,1:10}, {0:1.0,1:99}, {0:1.0,1:100}, {0:1.0,1:150}, \n",
    "     {0:1.0,1:200}, {0:1.0,1:300},{0:1.0,1:400},{0:1.0,1:500}, \n",
    "     {0:1.0,1:1000}, {0:10,1:1000},{0:100,1:1000} ]\n",
    "crange = np.arange(0.5, 20.0, 0.5)\n",
    "hyperparam_grid = {\"penalty\": [\"l1\", \"l2\"]\n",
    "                   ,\"C\": crange,\n",
    "                   \"solver\":['liblinear', 'newton-cholesky'],\n",
    "                   'class_weight':w\n",
    "                  }\n",
    "\n",
    "# logistic model classifier\n",
    "lg4 = LogisticRegression(random_state=13, max_iter=500)\n",
    "\n",
    "# define evaluation procedure\n",
    "grid = GridSearchCV(lg4, hyperparam_grid, scoring=\"roc_auc\", n_jobs=-1, refit=True)\n",
    "\n",
    "grid.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(f'Best score: {grid.best_score_} with param: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad4e114",
   "metadata": {},
   "source": [
    "### LogReg Model with Optimized Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "53a8d010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.6788321167883211\n",
      "Confusion Matrix: \n",
      "[[88 44]\n",
      " [ 0  5]]\n",
      "Area Under Curve:  0.8333333333333334\n",
      "Recall score: 1.0\n"
     ]
    }
   ],
   "source": [
    "lg5 = LogisticRegression(solver='liblinear', penalty='l1', C = 0.5, class_weight={0: 0.01, 1: 10}, random_state=13, max_iter=500,)\n",
    "\n",
    "lg5.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = lg5.predict(X_test)\n",
    "\n",
    "lg5_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_pred)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_pred)}')\n",
    "print('Area Under Curve: ', lg5_score)\n",
    "print(f'Recall score: {recall_score(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bbb5b3",
   "metadata": {},
   "source": [
    "After some hyperparameter tuning, we're left with a significantly improved AUC score however at the expense of a marked drop in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0bcbb488",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = {'LogReg':lg5_score}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396fb57d",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c093b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:employee-attrition] *",
   "language": "python",
   "name": "conda-env-employee-attrition-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
